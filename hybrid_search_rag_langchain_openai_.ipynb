{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/UdaraChamidu/Generative-AI/blob/main/hybrid_search_rag_langchain_openai_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Hybrid Search RAG** using Langchain and OpenAI"
      ],
      "metadata": {
        "id": "UVTPgcBZkA0h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pypdf -q\n",
        "!pip install langchain -q\n",
        "!pip install langchain_community -q\n",
        "!pip install langchain_openai -q\n",
        "!pip install langchain_chroma -q\n",
        "!pip install rank_bm25 -q  # calculate the spase vectors\n",
        "!pip install --upgrade numpy\n"
      ],
      "metadata": {
        "id": "wmxoMkkuj61i",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9af315e-0701-4d4a-b72a-94b58aa008f3"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (1.26.4)\n",
            "Collecting numpy\n",
            "  Downloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading numpy-2.2.4-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (16.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m16.4/16.4 MB\u001b[0m \u001b[31m35.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: numpy\n",
            "  Attempting uninstall: numpy\n",
            "    Found existing installation: numpy 1.26.4\n",
            "    Uninstalling numpy-1.26.4:\n",
            "      Successfully uninstalled numpy-1.26.4\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langchain-chroma 0.2.2 requires numpy<2.0.0,>=1.22.4; python_version < \"3.12\", but you have numpy 2.2.4 which is incompatible.\n",
            "tensorflow 2.18.0 requires numpy<2.1.0,>=1.26.0, but you have numpy 2.2.4 which is incompatible.\n",
            "numba 0.60.0 requires numpy<2.1,>=1.22, but you have numpy 2.2.4 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed numpy-2.2.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "import os\n",
        "from google.colab import userdata"
      ],
      "metadata": {
        "id": "vcD68Tw3sk8r"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize OpenAI LLM"
      ],
      "metadata": {
        "id": "GqffvL70spfo"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# Set OpenAI API key\n",
        "os.environ['OPENAI_API_KEY'] = userdata.get('OPENAI_API_KEY')\n",
        "\n",
        "# Initialize the ChatOpenAI model\n",
        "llm = ChatOpenAI(\n",
        "    model=\"gpt-3.5-turbo\",\n",
        "    temperature=0\n",
        ")"
      ],
      "metadata": {
        "id": "7fXGn56fsmLS"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Initialize Embedding Model"
      ],
      "metadata": {
        "id": "013w_y09sy-6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# for semantic search\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "embedding_model = OpenAIEmbeddings(model=\"text-embedding-3-small\")"
      ],
      "metadata": {
        "id": "k3DRzkVEstFq"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load PDF Document"
      ],
      "metadata": {
        "id": "6BIoEAjSt31K"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_community.document_loaders import PyPDFLoader\n",
        "\n",
        "loader=PyPDFLoader(\"codeprolk.pdf\")\n",
        "\n",
        "docs=loader.load()"
      ],
      "metadata": {
        "id": "1MWCjokQkcA6"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Split Documents into Chunks"
      ],
      "metadata": {
        "id": "Mfv3XtMquBWS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "\n",
        "splitter = RecursiveCharacterTextSplitter(chunk_size=250,chunk_overlap=30)\n",
        "\n",
        "chunks = splitter.split_documents(docs)"
      ],
      "metadata": {
        "id": "zeAeeVhUlCRb"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(chunks)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vdu_8gyFgV9c",
        "outputId": "031809ae-3285-473d-a699-33f7dbbc3905"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "33"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Semantic Search Retriever"
      ],
      "metadata": {
        "id": "W2nGrP5luaUh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_chroma import Chroma\n",
        "\n",
        "vectorstore=Chroma.from_documents(chunks, embedding_model)\n",
        "\n",
        "vectorstore_retreiver = vectorstore.as_retriever(search_kwargs={\"k\": 2})\n",
        "# k = number of documents need to be retrieved"
      ],
      "metadata": {
        "id": "XfUaqBWglUeU"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorstore_retreiver\n",
        "\n",
        "# previous same things ...."
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AsPUohhYvXAo",
        "outputId": "3ac23555-6708-4b09-e498-8f3c0bdadf85"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7cb3200ce3d0>, search_kwargs={'k': 2})"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Keyword Search Retriever"
      ],
      "metadata": {
        "id": "G2wSq4RxvEX2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# new things happenning from here\n",
        "\n",
        "from langchain.retrievers import BM25Retriever\n",
        "\n",
        "keyword_retriever = BM25Retriever.from_documents(chunks)\n",
        "\n",
        "keyword_retriever.k =  2"
      ],
      "metadata": {
        "id": "H-cmQhdFvDp_"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "keyword_retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PvBaQc6RvTMn",
        "outputId": "34e441a6-8be6-41ff-e24c-702f009739c8"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7cb319340850>, k=2)"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create Hybrid Search Retriever"
      ],
      "metadata": {
        "id": "kG98eMbvvoLg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.retrievers import EnsembleRetriever\n",
        "\n",
        "ensemble_retriever = EnsembleRetriever(retrievers = [vectorstore_retreiver, keyword_retriever], weights = [0.5, 0.5])\n",
        "# we can enter all retrievers here now we are using.\n",
        "# weights also can be give for different retrievers."
      ],
      "metadata": {
        "id": "-RpEYEGrveKI"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ensemble_retriever"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zCEs1P2VmcfE",
        "outputId": "869f0ff7-2d51-40d3-fbe6-d0ffdbbcbc9d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "EnsembleRetriever(retrievers=[VectorStoreRetriever(tags=['Chroma', 'OpenAIEmbeddings'], vectorstore=<langchain_chroma.vectorstores.Chroma object at 0x7cb3200ce3d0>, search_kwargs={'k': 2}), BM25Retriever(vectorizer=<rank_bm25.BM25Okapi object at 0x7cb319340850>, k=2)], weights=[0.5, 0.5])"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Define Prompt Template"
      ],
      "metadata": {
        "id": "a4Wz0GFHwChG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# Define a message template for the chatbot\n",
        "message = \"\"\"\n",
        "Answer this question using the provided context only.\n",
        "\n",
        "{question}\n",
        "\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "# Create a chat prompt template from the message\n",
        "prompt = ChatPromptTemplate.from_messages([(\"human\", message)])"
      ],
      "metadata": {
        "id": "pWZq6SlnwJOw"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create RAG Chain with Hybrid Search"
      ],
      "metadata": {
        "id": "-gzSvYwbwOSf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain = (\n",
        "    {\n",
        "      \"context\": ensemble_retriever,  # use hybrid ...\n",
        "      \"question\": RunnablePassthrough()\n",
        "    }\n",
        "    | prompt\n",
        "    | llm\n",
        ")"
      ],
      "metadata": {
        "id": "GpKnaG1dwXtA"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Invoke RAG Chain with Example Questions"
      ],
      "metadata": {
        "id": "70KjkagfwxF3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "response = chain.invoke(\"what are the popular videos in codeprolk\")\n",
        "\n",
        "print(response.content)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DIQsSfiCw1Gf",
        "outputId": "8f18520b-fe38-4db0-a19e-22fcb360de82"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "The popular videos in CodePRO LK are those that have assisted viewers in their learning journeys.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keyword_retriever, vectorstore_retreiver, ensemble_retriever"
      ],
      "metadata": {
        "id": "XbYGTJGqw90H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in keyword_retriever.invoke(\"what are the popular videos in codeprolk\"):\n",
        "  print(doc.page_content)\n",
        "  print(\"---------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z8VxZ6G3lZrX",
        "outputId": "bf4670c1-ae6b-4a2a-c3d7-66aa82250414"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "appreciation and sharing how the videos have assisted them in their learning journeys. \n",
            "Impact \n",
            "The CodePRO LK YouTube channel has played a significant role in democratizing tech\n",
            "---------------------\n",
            "industry, ensuring that learners are well-prepared for real-world challenges. \n",
            "Enhanced Learning Tools \n",
            "The platform plans to integrate more interactive and adaptive learning tools to personalize the\n",
            "---------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in vectorstore_retreiver.invoke(\"what are the popular videos in codeprolk\"):\n",
        "  print(doc.page_content)\n",
        "  print(\"---------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YdgnZ9j6llq3",
        "outputId": "04dae9e8-80cb-4ac6-824d-39caf4d3b54e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "appreciation and sharing how the videos have assisted them in their learning journeys. \n",
            "Impact \n",
            "The CodePRO LK YouTube channel has played a significant role in democratizing tech\n",
            "---------------------\n",
            "CodePRO LK is committed to strengthening its community through regular engagement \n",
            "activities such as webinars, live coding sessions, hackathons, and tech talks. These events\n",
            "---------------------\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for doc in ensemble_retriever.invoke(\"what are the popular videos in codeprolk\"):\n",
        "  print(doc.page_content)\n",
        "  print(\"---------------------\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JNfCN2L1lAhe",
        "outputId": "f615b991-d189-48f4-a0a2-451c9acc29e8"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "appreciation and sharing how the videos have assisted them in their learning journeys. \n",
            "Impact \n",
            "The CodePRO LK YouTube channel has played a significant role in democratizing tech\n",
            "---------------------\n",
            "CodePRO LK is committed to strengthening its community through regular engagement \n",
            "activities such as webinars, live coding sessions, hackathons, and tech talks. These events\n",
            "---------------------\n",
            "industry, ensuring that learners are well-prepared for real-world challenges. \n",
            "Enhanced Learning Tools \n",
            "The platform plans to integrate more interactive and adaptive learning tools to personalize the\n",
            "---------------------\n"
          ]
        }
      ]
    }
  ]
}